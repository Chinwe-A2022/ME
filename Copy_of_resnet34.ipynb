{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvx36pkbIXs3amSaYyyrU5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mtG56xenUXob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMQjr2F84O27"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNUTTyj4UWd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "5A-P4-0v4Zzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conda install pytorch torchvision torchaudio cpuonly -c pytorch"
      ],
      "metadata": {
        "id": "_a5NaJ8x4bIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "KKYkpNhD4eux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "5XjEZ-du4hMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "zkcLp7aE4ilE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os                       # for working with files\n",
        "import numpy as np              # for numerical computationss\n",
        "import torch                    # Pytorch module\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
        "import torch.nn as nn           # for creating  neural networks\n",
        "from torch.utils.data import DataLoader # for dataloaders\n",
        "from PIL import Image           # for checking images\n",
        "import torch.nn.functional as F # for functions for calculating loss\n",
        "import torchvision.transforms as transforms   # for transforming images into tensors\n",
        "from torchvision.utils import make_grid       # for data checking\n",
        "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
        "from torchsummary import summary              # for getting the summary of our model\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "zgUTWBFT4kWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "_BjJIm0b4mPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "ihUr7gV44oPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show scikit-learn"
      ],
      "metadata": {
        "id": "ieJTO6dD4p0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "-DxGl4c_4rVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import tensorflow_hub as hub\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import cv2 as cv\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "DTatI0Pm4s_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "0AYarF5x4u1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.losses.sparse_softmax_cross_entropy"
      ],
      "metadata": {
        "id": "SxkDryCK4xBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import OneCycleLR"
      ],
      "metadata": {
        "id": "HLKRALJV4yl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/sample_data/Chinesetallow_whitemodel.zip','r') #Opens the zip file\n",
        "zip_ref.extractall('/tmp')  #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "WoNYapy1UdtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target dimensions\n",
        "root_dir = \"E:/Chinesetallow_originalmodel\"\n",
        "target_size = (300, 300)\n",
        "\n",
        "# Walk through the directory\n",
        "for subdir, dirs, files in os.walk(root_dir):\n",
        "    for file in files:\n",
        "        # Check if the file is an image (you can add or remove file types as needed)\n",
        "        if file.endswith('.png'):\n",
        "            with Image.open(os.path.join(subdir, file)) as img:\n",
        "                img_resized = img.resize(target_size)\n",
        "\n",
        "              # Save the resized image back to the filesystem\n",
        "                img_resized.save(os.path.join(subdir, f'{file}'))\n",
        "\n",
        "    print('All images have been resized.')"
      ],
      "metadata": {
        "id": "xj8-YIyO4zcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"E:/Chinesetallow_originalmodel\"\n",
        "train_dir = data_dir + \"/TRAIN\"\n",
        "valid_dir = data_dir + \"/VALIDATE\"\n",
        "image_files = os.listdir(train_dir)\n",
        "\n",
        "print (image_files)\n",
        "print(\"Total classes are: {}\".format(len(image_files)))"
      ],
      "metadata": {
        "id": "aqbafM2A428T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize sets to store unique plants and colors\n",
        "unique_classes = set()\n",
        "\n",
        "# Loop through each file name and extract the plant and color\n",
        "for filename in image_files:\n",
        "    # Split the filename on underscores and the period before the file extension\n",
        "    parts = filename.split('_')\n",
        "    plants = parts[0]\n",
        "    health = parts[-1].split('.')[0]\n",
        "\n",
        "    # Add the extracted plant and color to the sets\n",
        "    unique_classes.add(health)\n",
        "\n",
        "# Print the number of unique plants and colors\n",
        "print(f\"Number of unique colors: {len(unique_classes)}\")\n",
        "print(f\"Unique Plants health conditions are: \\n{unique_classes}\")"
      ],
      "metadata": {
        "id": "iacL_XXe46Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nums = {}\n",
        "for files in image_files:\n",
        "    nums[files] = len(os.listdir(train_dir + '/' + files))\n",
        "\n",
        "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
        "\n",
        "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
        "img_per_class"
      ],
      "metadata": {
        "id": "gZKcQU8e47Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = [n for n in range(3)] #CHANGE RANGE\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.bar(index, [n for n in nums.values()], width= 0.8)\n",
        "plt.xlabel('Plants/Image_files', fontsize=10)\n",
        "plt.ylabel('No of images available', fontsize=10)\n",
        "plt.xticks(index, image_files, fontsize=10, rotation=90)\n",
        "plt.title('Images per class.')"
      ],
      "metadata": {
        "id": "Cq2qvW7649ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = 0\n",
        "for value in nums.values():\n",
        "    n_train += value\n",
        "print(f\"There are {n_train} images for training\")"
      ],
      "metadata": {
        "id": "2PO0aawo4_ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20"
      ],
      "metadata": {
        "id": "-45ZQEBU5BNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize the image\n",
        "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
        "    # Normalize with the mean and standard deviation used for ResNet training\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "a5zrd80V5C58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets for validation and training\n",
        "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
        "valid = ImageFolder(valid_dir, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "NluhJpy85EUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaders for training and validation\n",
        "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "valid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "-MA9xnpg5FK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train[0]\n",
        "print(img.shape, label)"
      ],
      "metadata": {
        "id": "BYV4nq4f5K9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for checking some images from training dataset\n",
        "def show_image(image, label):\n",
        "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
        "    plt.imshow(image.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "9EdK4Gz55Mic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(*train[2400])"
      ],
      "metadata": {
        "id": "XaSnWzZv5N2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageFolder('E:/Chinesetallow_originalmodel/TRAIN', transform=transform)"
      ],
      "metadata": {
        "id": "8vBWFdf25Pl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader\n",
        "data_loader = DataLoader(dataset, batch_size=20, shuffle=True)"
      ],
      "metadata": {
        "id": "msenLjGt5RTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(data_loader):\n",
        "    for images, labels in data_loader:\n",
        "        fig, ax = plt.subplots(figsize=(30, 30))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        # Make sure to permute the dimensions to match what matplotlib expects\n",
        "        ax.imshow(make_grid(images, nrow=5).permute(1, 2, 0))\n",
        "        break\n",
        "\n",
        "# Call the function with your DataLoader\n",
        "show_batch(data_loader)"
      ],
      "metadata": {
        "id": "Ckn3EMhE5Sxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for moving data into GPU (if available)\n",
        "def get_default_device():\n",
        "    # if torch.cuda.is_available:\n",
        "    #     return torch.device(\"cuda\")\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "# for loading in the device (GPU if available else CPU)\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "Fe9txnKO5Ub8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moving data into CPU\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)"
      ],
      "metadata": {
        "id": "myoddH3J5WGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 300, 300"
      ],
      "metadata": {
        "id": "XbKr1Jvg5XVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing and augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Data preprocessing for validation\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "SXL48JM05ZGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the BasicBlock\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "nIN7ONfH5bCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet class\n",
        "class ResNet34(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=3):\n",
        "        super(ResNet34, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)  # Generate prediction\n",
        "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
        "        acc = accuracy(out, labels)  # Assuming you have an accuracy function\n",
        "        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
        "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()  # Combine loss\n",
        "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
        "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy}  # Combine accuracies\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(f\"Epoch [{epoch}], train_loss: {result['train_loss']:.4f}, val_loss: {result['val_loss']:.4f}, val_acc: {result['val_accuracy']:.4f}\")\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "WwNgRnJF5id1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = ResNet34(BasicBlock, [3, 4, 6, 3], num_classes=3)\n",
        "\n",
        "# getting summary of the model\n",
        "INPUT_SHAPE = (3, 64, 64)\n",
        "print(summary(model.cpu(), (INPUT_SHAPE)))"
      ],
      "metadata": {
        "id": "45fh1ep75jPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet34(BasicBlock, [3, 4, 6, 3], num_classes=3).to(device)"
      ],
      "metadata": {
        "id": "vUZOiE3V5mqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, patience=5, weight_decay=1e-4, grad_clip=0.5, opt_func=torch.optim.SGD):\n",
        "    # torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    sched = OneCycleLR(optimizer, max_lr=max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record and update learning rates\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "        # Validation Phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "#         # Early stopping logic\n",
        "#         val_loss = result['val_loss']\n",
        "#         if val_loss < best_val_loss:\n",
        "#             best_val_loss = val_loss\n",
        "#             patience_counter = 0\n",
        "#         else:\n",
        "#             patience_counter += 1\n",
        "\n",
        "#         if patience_counter >= patience:\n",
        "#             print(\"Stopping early due to no improvement in validation loss.\")\n",
        "#             break\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "C_59tQPK5oxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train[0]\n",
        "print(img.shape, label)"
      ],
      "metadata": {
        "id": "Lc7D2hrV5qea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = [evaluate(model, valid_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "jBtC-x3Q5ryQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet34(BasicBlock, [3, 4, 6, 3], num_classes=3)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_loader = train_dl # Define your training data loader\n",
        "val_loader = valid_dl # Define your validation data loader\n",
        "epochs = 20\n",
        "# patience = 5"
      ],
      "metadata": {
        "id": "kURlFTtP5tf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = fit_one_cycle(epochs=epochs, max_lr=5e-4, model=model, train_loader=train_loader, val_loader=val_loader, weight_decay=1e-4, grad_clip=0.5, opt_func=optim.Adam)"
      ],
      "metadata": {
        "id": "-gKsYIBZ5vDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_accuracy'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning rate')\n",
        "    plt.title('Learning Rate vs. Batch no.');"
      ],
      "metadata": {
        "id": "eAptV-sZ5yEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)"
      ],
      "metadata": {
        "id": "cIpxsug251e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = \"\"\n",
        "test = ImageFolder(test_dir, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "IujLxUdC53Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = sorted(os.listdir(test_dir + '/test')) # since images in test folder are in alphabetical order\n",
        "test_images"
      ],
      "metadata": {
        "id": "DQCkuB2C56Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img, model):\n",
        "    \"\"\"Converts image to array and return the predicted class\n",
        "        with highest probability\"\"\"\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "\n",
        "    return train.classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "4iCwDTUR57T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting first image\n",
        "img, label = test[0]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', test_images[0], ', Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "DkyktHoU59nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting all predictions (actual label vs predicted)\n",
        "for i, (img, label) in enumerate(test):\n",
        "    print('Label:', test_images[i], ', Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "FE_BFU0U5_yO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
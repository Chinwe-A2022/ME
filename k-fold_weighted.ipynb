{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ace8f4-7dbb-4e2d-a37c-42c164c0abc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import subprocess\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "EXCEL_PATH = \"C:/Users/chinw/Downloads/K-FOLD_Chinesetallow_AceticAcid.xlsx\"\n",
    "SHEET_NAME = \"Sheet1\"\n",
    "TIMESTEPS = 6                 # shorter windows more samples on small data\n",
    "THRESHOLD_FIXED = 470.0       \n",
    "REQUESTED_FOLDS = 5           \n",
    "EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "UNITS = 50\n",
    "DROPOUT = 0.3\n",
    "LR = 1e-3\n",
    "BATCH = 16\n",
    "SEED = 47\n",
    "\n",
    "def _ensure_openpyxl():\n",
    "    try:\n",
    "        import openpyxl  \n",
    "    except Exception:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"openpyxl\"])\n",
    "        import importlib; importlib.invalidate_caches()\n",
    "        import openpyxl \n",
    "_ensure_openpyxl()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e08567-8263-4d31-afba-11ba71de426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_tidy(path: str, sheet: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Excel not found: {path}\")\n",
    "    raw = pd.read_excel(path, sheet_name=sheet, engine=\"openpyxl\")\n",
    "\n",
    "    labels = raw.iloc[:, 0].ffill()\n",
    "    date_row = pd.to_datetime(raw.iloc[0, 1:].values, errors=\"coerce\")\n",
    "    values = raw.iloc[1:, 1:]\n",
    "    values.index = labels.iloc[1:]\n",
    "    values.columns = date_row\n",
    "\n",
    "    plant_re = re.compile(r\"sapium\", re.IGNORECASE)\n",
    "    metrics = {\"LIGHT\", \"MOISTURE\", \"TEMPERATURE\", \"FERTILITY\"}\n",
    "\n",
    "    blocks = []\n",
    "    cur = {\"Plant\": None, \"LIGHT\": None, \"MOISTURE\": None, \"TEMPERATURE\": None, \"FERTILITY\": None}\n",
    "    for label, row in values.iterrows():\n",
    "        if isinstance(label, str) and plant_re.search(label):\n",
    "            if cur[\"Plant\"] and cur[\"MOISTURE\"] is not None and cur[\"FERTILITY\"] is not None:\n",
    "                blocks.append(cur)\n",
    "            cur = {\"Plant\": label, \"LIGHT\": None, \"MOISTURE\": None, \"TEMPERATURE\": None, \"FERTILITY\": None}\n",
    "        elif label in metrics:\n",
    "            cur[label] = pd.to_numeric(row, errors=\"coerce\")\n",
    "    if cur[\"Plant\"] and cur[\"MOISTURE\"] is not None and cur[\"FERTILITY\"] is not None:\n",
    "        blocks.append(cur)\n",
    "\n",
    "    if not blocks:\n",
    "        raise ValueError(\"No plant blocks with MOISTURE and FERTILITY found.\")\n",
    "\n",
    "    frames = []\n",
    "    for b in blocks:\n",
    "        frames.append(pd.DataFrame({\n",
    "            \"Plant\": b[\"Plant\"],\n",
    "            \"Date\": b[\"MOISTURE\"].index,\n",
    "            \"Moisture\": b[\"MOISTURE\"].values,\n",
    "            \"Fertility\": b[\"FERTILITY\"].values\n",
    "        }))\n",
    "    ts = pd.concat(frames, ignore_index=True)\n",
    "    ts = ts.dropna(subset=[\"Moisture\", \"Fertility\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90300ea8-7edf-47ce-a0d8-a1ccd459bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_variation_scaled(df: pd.DataFrame) -> np.ndarray:\n",
    "    v = np.abs((df[\"Moisture\"].values - df[\"Fertility\"].values).astype(float))\n",
    "    return MinMaxScaler().fit_transform(v.reshape(-1, 1)).ravel()\n",
    "\n",
    "def build_windows(series_1d: np.ndarray, labels_1d: np.ndarray, T: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X, y = [], []\n",
    "    for t in range(T - 1, len(series_1d)):\n",
    "        X.append(series_1d[t - T + 1: t + 1].reshape(T, 1))\n",
    "        y.append(labels_1d[t])  # label at window end\n",
    "    X = np.asarray(X, np.float32)\n",
    "    y = np.asarray(y)\n",
    "    if X.size == 0:\n",
    "        raise ValueError(\"No windows built; reduce TIMESTEPS.\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "694d1456-59b5-4742-8682-04af3ee1b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(timesteps: int) -> Sequential:\n",
    "    # Input layer avoids Keras warning\n",
    "    m = Sequential([\n",
    "        Input(shape=(timesteps, 1)),\n",
    "        LSTM(50),\n",
    "        Dropout(0.3),  # why: regularization on small data\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    m.compile(optimizer=Adam(learning_rate=LR), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "def class_weights(y: np.ndarray) -> Dict[int, float]:\n",
    "    c0 = int((y == 0).sum()); c1 = int((y == 1).sum())\n",
    "    tot = c0 + c1\n",
    "    return {0: tot / (2 * max(c0, 1)), 1: tot / (2 * max(c1, 1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "970b0f91-4dd7-4930-8d3d-320514628d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_with_cm(y_true: np.ndarray, y_prob: np.ndarray) -> Dict[str, float]:\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    out = {\n",
    "        \"acc\": accuracy_score(y_true, y_pred),\n",
    "        \"bacc\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"prec_macro\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"rec_macro\":  recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"f1_macro\":   f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"prec_weighted\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"rec_weighted\":  recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"f1_weighted\":   f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"ap\":  average_precision_score(y_true, y_prob),\n",
    "    }\n",
    "    try:\n",
    "        out[\"auc\"] = roc_auc_score(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        out[\"auc\"] = float(\"nan\")\n",
    "    out[\"cm\"] = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4626fe0-40e4-4c27-adfb-d8368f3afbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows built: X=(40, 6, 1), end-point positives@470.0=0, total=40\n",
      "WARNING: 470 produced a single class. Falling back to median threshold: 231.604\n",
      "Using threshold: 231.604; positives=20, negatives=20\n",
      "Stratified K-fold k=5\n",
      "[Fold 1] Acc=0.750 BAcc=0.750 F1(macro)=0.733 F1(wtd)=0.733 AP=1.000 AUC=1.0\n",
      "WARNING:tensorflow:From C:\\Users\\chinw\\anaconda3\\envs\\Tensorflow\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "[Fold 2] Acc=0.750 BAcc=0.750 F1(macro)=0.750 F1(wtd)=0.750 AP=0.646 AUC=0.6875\n",
      "[Fold 3] Acc=1.000 BAcc=1.000 F1(macro)=1.000 F1(wtd)=1.000 AP=1.000 AUC=1.0\n",
      "[Fold 4] Acc=0.375 BAcc=0.375 F1(macro)=0.273 F1(wtd)=0.273 AP=0.729 AUC=0.625\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A95B5223E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Fold 5] Acc=0.500 BAcc=0.500 F1(macro)=0.467 F1(wtd)=0.467 AP=0.747 AUC=0.6875\n",
      "\n",
      "=== Mean metrics across folds ===\n",
      "acc: 0.6750\n",
      "bacc: 0.6750\n",
      "prec_macro: 0.6595\n",
      "rec_macro: 0.6750\n",
      "f1_macro: 0.6445\n",
      "prec_weighted: 0.6595\n",
      "rec_weighted: 0.6750\n",
      "f1_weighted: 0.6445\n",
      "ap: 0.8244\n",
      "auc: 0.8000\n",
      "\n",
      "=== Aggregate Confusion Matrix (sum over folds; labels=[0,1]) ===\n",
      "[[10 10]\n",
      " [ 3 17]]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "    np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "    # Data\n",
    "    ts = load_and_tidy(EXCEL_PATH, SHEET_NAME)\n",
    "    var = build_variation_scaled(ts)\n",
    "    fert = ts[\"Fertility\"].values.astype(float)\n",
    "\n",
    "    # Windows over the whole data\n",
    "    X_all, fert_end = build_windows(var, fert, TIMESTEPS)\n",
    "    print(f\"Windows built: X={X_all.shape}, end-point positives@{THRESHOLD_FIXED}={(fert_end>THRESHOLD_FIXED).sum()}, total={len(fert_end)}\")\n",
    "\n",
    "    # Classification target: try fixed threshold, else fallback to median\n",
    "    y_all = (fert_end > THRESHOLD_FIXED).astype(int)\n",
    "    if np.unique(y_all).size < 2:\n",
    "        thr = float(np.median(fert_end))\n",
    "        y_all = (fert_end > thr).astype(int)\n",
    "        print(f\"WARNING: 470 produced a single class. Falling back to median threshold: {thr:.3f}\")\n",
    "    else:\n",
    "        thr = THRESHOLD_FIXED\n",
    "    print(f\"Using threshold: {thr:.3f}; positives={int(y_all.sum())}, negatives={int((y_all==0).sum())}\")\n",
    "\n",
    "    # K-fold (stratified) with safe k\n",
    "    min_class = int(np.bincount(y_all, minlength=2).min())\n",
    "    if min_class < 2:\n",
    "        raise ValueError(\"Not enough samples of one class after windowing. Reduce TIMESTEPS or collect more data.\")\n",
    "    k = max(2, min(REQUESTED_FOLDS, min_class))\n",
    "    print(f\"Stratified K-fold k={k}\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "\n",
    "    metrics_list: List[Dict] = []\n",
    "    agg_cm = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "    for fold, (tr, va) in enumerate(skf.split(X_all, y_all), start=1):\n",
    "        X_tr, y_tr = X_all[tr], y_all[tr]\n",
    "        X_va, y_va = X_all[va], y_all[va]\n",
    "\n",
    "        model = build_model(TIMESTEPS)\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True)\n",
    "        model.fit(X_tr, y_tr,\n",
    "                  validation_data=(X_va, y_va),\n",
    "                  epochs=EPOCHS, batch_size=BATCH,\n",
    "                  class_weight=class_weights(y_tr),\n",
    "                  callbacks=[es], verbose=0)\n",
    "\n",
    "        y_prob = model.predict(X_va, verbose=0).ravel()\n",
    "        m = metrics_with_cm(y_va, y_prob)\n",
    "        agg_cm += m[\"cm\"]\n",
    "\n",
    "        print(f\"[Fold {fold}] Acc={m['acc']:.3f} BAcc={m['bacc']:.3f} \"\n",
    "              f\"F1(macro)={m['f1_macro']:.3f} F1(wtd)={m['f1_weighted']:.3f} \"\n",
    "              f\"AP={m['ap']:.3f} AUC={m['auc'] if not np.isnan(m['auc']) else 'na'}\")\n",
    "        # Uncomment to see each fold's CM\n",
    "        # print(\"CM:\\n\", m[\"cm\"])\n",
    "\n",
    "        metrics_list.append({k: v for k, v in m.items() if k != \"cm\"})\n",
    "        K.clear_session()\n",
    "\n",
    "    # Averages across folds (ignore NaN AUC)\n",
    "    keys = [\"acc\",\"bacc\",\"prec_macro\",\"rec_macro\",\"f1_macro\",\"prec_weighted\",\"rec_weighted\",\"f1_weighted\",\"ap\",\"auc\"]\n",
    "    means = {k: float(np.nanmean([m[k] for m in metrics_list])) for k in keys}\n",
    "    print(\"\\n=== Mean metrics across folds ===\")\n",
    "    for k_, v in means.items():\n",
    "        print(f\"{k_}: {v:.4f}\" if not np.isnan(v) else f\"{k_}: na\")\n",
    "\n",
    "    print(\"\\n=== Aggregate Confusion Matrix (sum over folds; labels=[0,1]) ===\")\n",
    "    print(agg_cm)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414d89c-9833-46bf-ac01-fc96fe55cd70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
